{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da6419b-966a-4a2b-8175-9fdecd142732",
   "metadata": {},
   "source": [
    "# Question - 1\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc06d05-89c2-4013-bb22-a2f459c0610a",
   "metadata": {},
   "source": [
    "1). Independence of Observations:\n",
    "\n",
    "*. Assumption: Observations in each group should be independent of each other. This means that the value of one observation should not be influenced by or dependent on the value of another observation.\n",
    "\n",
    "*. Violation Example: If you are conducting an ANOVA on test scores of students in different classrooms, and students within the same classroom collaborate on their tests, violating the independence assumption.\n",
    "\n",
    "2). Homogeneity of Variances (Homoscedasticity):\n",
    "\n",
    "*. Assumption: The variances of the different groups being compared should be approximately equal. In other words, the spread of the data points should be similar across all groups.\n",
    "\n",
    "*. Violation Example: If you are comparing the yields of different types of crops, and one crop type consistently shows much greater variation in yield compared to others, this would violate the homogeneity of variances assumption.\n",
    "\n",
    "3). Normality of Residuals:\n",
    "\n",
    "*. Assumption: The residuals (the differences between the observed values and the group means) should follow a normal distribution. This assumption applies to the residuals, not necessarily to the original data.\n",
    "\n",
    "*. Violation Example: If the residuals do not follow a normal distribution and are skewed or have heavy tails, it can lead to inaccurate p-values and confidence intervals.\n",
    "\n",
    "4). Random Sampling:\n",
    "\n",
    "*. Assumption: The samples selected from each group should be random and representative of the population from which they are drawn.\n",
    "\n",
    "*. Violation Example: If you are conducting an ANOVA on income levels across different regions and your samples are not randomly selected but, for example, biased towards a certain income group, it can introduce bias into your results.\n",
    "\n",
    "5). Independence of Groups:\n",
    "\n",
    "*. Assumption: The groups or treatments being compared should be mutually exclusive, and individuals or items should belong to only one group.\n",
    "*. Violation Example: If you are conducting an ANOVA to compare the effectiveness of three different advertising campaigns, and some individuals are exposed to multiple campaigns, it can violate this assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746517b-b732-44f0-ada8-d204cf01ef9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb12fd-7afe-43c3-9df1-e87218c95d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e247205a-d9b8-4af1-8ba5-abfc757a5c9c",
   "metadata": {},
   "source": [
    "# Question - 2\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed6d7da-240f-4f33-b72e-5d777630a973",
   "metadata": {},
   "source": [
    "1). One-Way ANOVA:\n",
    "\n",
    "*. Situation: One-Way ANOVA is used when you have one independent variable (factor) with more than two levels or groups, and you want to compare the means of those groups to determine if there are any statistically significant differences.\n",
    "\n",
    "*. Example: Suppose you want to compare the test scores of students who have received three different types of tutoring (Group A, Group B, and Group C) to see if there are differences in their mean scores.\n",
    "\n",
    "\n",
    "2). Two-Way ANOVA:\n",
    "\n",
    "*. Situation: Two-Way ANOVA is used when you have two independent variables (factors) and you want to determine the effects of these two factors on a dependent variable. It examines not only the main effects of each factor but also their interaction effect.\n",
    "\n",
    "*. Example: Suppose you are conducting a study to analyze the effects of both diet (Factor 1: Diet A, Diet B) and exercise (Factor 2: Exercise Yes/No) on weight loss. Two-Way ANOVA allows you to assess the impact of diet, exercise, and their interaction on weight loss.\n",
    "\n",
    "\n",
    "3). Repeated Measures ANOVA:\n",
    "\n",
    "*. Situation: Repeated Measures ANOVA is used when you have measured the same subjects or items under multiple conditions or time points. It is used to determine if there are significant differences between the conditions and whether those differences change over time.\n",
    "\n",
    "*. Example: Imagine a study where the same group of participants is tested for their reaction times under three different conditions: before, during, and after a training program. Repeated Measures ANOVA helps assess whether the reaction times change significantly across these time points.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ">>. In summary:\n",
    "\n",
    "a). One-Way ANOVA is used when you have one factor with multiple levels or groups.\n",
    "\n",
    "b). Two-Way ANOVA is used when you have two factors, and you want to examine their main effects and interaction.\n",
    "\n",
    "c). Repeated Measures ANOVA is used when you have measurements on the same subjects or items under multiple conditions or time points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87798da1-4184-4931-8865-125af53ff211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a30a5-ac77-4e4e-9e15-308821caea36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5193ae9-2380-4e03-82a9-2057248e464b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72ee0f75-5d3a-4ce6-8144-9f26e74c3b23",
   "metadata": {},
   "source": [
    "# Quesiton - 3\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfaa67c-c8ba-4326-95a6-afc138a69b6f",
   "metadata": {},
   "source": [
    "The partitioning of variance in Analysis of Variance (ANOVA) is a fundamental concept that helps explain the sources of variation in a dataset and how these sources contribute to the overall variability in the dependent variable. Understanding this concept is crucial in ANOVA because it allows researchers to assess the relative importance of different factors or sources of variation in a statistical analysis. It also helps in drawing conclusions about the significance of these factors and making informed decisions based on the results.\n",
    "\n",
    "In ANOVA, the total variance in the dataset (the total variability in the dependent variable) is divided into several components, which are as follows:\n",
    "\n",
    "1). Total Variance (Total Sum of Squares, SST):\n",
    "\n",
    "The total variance represents the overall variability in the data. It measures how much the individual data points differ from the overall mean.\n",
    "\n",
    "\n",
    "2). Between-Group Variance (Between-Group Sum of Squares, SSB):\n",
    "\n",
    "This component of variance quantifies the variation between the different groups or treatments in your dataset. It measures how much the group means differ from the overall mean.\n",
    "\n",
    "\n",
    "3). Within-Group Variance (Within-Group Sum of Squares, SSW):\n",
    "\n",
    "Within-group variance measures the variation within each group or treatment. It represents how much individual data points within a group differ from their respective group mean.\n",
    "\n",
    "\n",
    ">. The relationship between these components is expressed by the ANOVA identity:\n",
    "\n",
    "SST=SSB+SSW\n",
    "\n",
    "***. Understanding this partitioning of variance is essential for several reasons:\n",
    "\n",
    "a). Assessing Significance: By comparing the between-group variance to the within-group variance, ANOVA determines whether there are statistically significant differences among the groups. If the between-group variance is much larger than the within-group variance, it suggests that the groups are different, and the differences are unlikely to be due to random chance.\n",
    "\n",
    "b). . Identifying Influential Factors: It helps researchers identify which factors or groups are contributing the most to the observed differences in the dependent variable. This is valuable for understanding the factors that are driving the outcomes.\n",
    "\n",
    "c). Model Interpretation: Understanding the partitioning of variance aids in interpreting the ANOVA model and its results. Researchers can explain how much of the total variation in the dependent variable is explained by the factors they are studying.\n",
    "\n",
    "d). Model Comparison: Researchers can use the partitioning of variance to compare different models. For example, they can assess whether adding a new factor to the model significantly reduces the within-group variance and improves the model's explanatory power.\n",
    "\n",
    "e). Effect Size: It allows for the calculation of effect size measures, such as eta-squared or partial eta-squared, which quantify the proportion of total variance attributable to the factors in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352fd18f-52a2-4867-be3b-1e5cc0cd7e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086cda35-8b22-4718-b094-5538dabe145c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da394a0a-d5d0-41c7-a403-13b58056256b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1600873-5fdf-460e-95be-31ab89574ddc",
   "metadata": {},
   "source": [
    "# Question - 4\n",
    "ans - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5308cd-48fc-469e-916f-bed3805627ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a92fad01-8e56-4380-bad9-947742ed0700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sum of squares is 40.833333333333336\n",
      "explained sum of squares is 32.33333333333331\n",
      "residual sum of squares is 8.5\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'group': ['A','A','B','B','C', 'C'],\n",
    "                   'value':[10,12,15,18,14,16]})\n",
    "df\n",
    "\n",
    "model = ols('value ~ group' , data = df).fit()\n",
    "\n",
    "\n",
    "# SST sum of total squares\n",
    "\n",
    "sst = sum((df['value'] - df['value'].mean())**2)\n",
    "print(f\"total sum of squares is {sst}\")\n",
    "\n",
    "#SSE explained sum of squares\n",
    "\n",
    "sse = sum((model.fittedvalues - df['value'].mean())**2)\n",
    "print(f\"explained sum of squares is {sse}\")\n",
    "\n",
    "\n",
    "# SSR residual sum of squares\n",
    "\n",
    "ssr = sum((df['value'] - model.fittedvalues)**2)\n",
    "print(f\"residual sum of squares is {ssr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e38e1-8861-4dc4-822e-c98dfbabb53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27935ca-0ee6-4a24-a8b5-de89a2af0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dbf0b7-7f0e-4b34-8382-94875eab1847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd9f5c21-4c21-498e-80c0-9e7e6310b4d6",
   "metadata": {},
   "source": [
    "# Question - 5\n",
    "ans - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd18e50-6936-46f3-83f9-3b7ef2b1f08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 sum_sq   df          F    PR(>F)\n",
      "factor1          55.125  1.0  11.307692  0.028234\n",
      "factor2           0.125  1.0   0.025641  0.880541\n",
      "factor1:factor2   0.125  1.0   0.025641  0.880541\n",
      "Residual         19.500  4.0        NaN       NaN\n",
      "main effect for factor1 is 55.12499999999986\n",
      "main effect for factor2 is 0.12500000000000114\n",
      "interaction effect is 0.12500000000000025\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "df = pd.DataFrame({'factor1': ['A', 'A', 'B', 'B', 'A', 'A', 'B', 'B'],\n",
    "                     'factor2': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
    "                     'value': [10, 12, 8, 9, 15, 14, 7, 6]})\n",
    "\n",
    "\n",
    "# fit a Two way anova model\n",
    "\n",
    "formula ='value ~ factor1 * factor2'\n",
    "model = ols(formula , data = df).fit()\n",
    "\n",
    "\n",
    "anova_table = sm.stats.anova_lm(model , typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "maineffect_factor1 = anova_table['sum_sq']['factor1'] / anova_table['df']['factor1']\n",
    "print(f\"main effect for factor1 is {maineffect_factor1}\")\n",
    "\n",
    "\n",
    "maineffect_factor2 = anova_table['sum_sq']['factor2'] / anova_table['df']['factor2']\n",
    "print(f\"main effect for factor2 is {maineffect_factor2}\")\n",
    "\n",
    "\n",
    "interaction_effect = anova_table['sum_sq']['factor1:factor2'] / anova_table['df']['factor1:factor2']\n",
    "print(f\"interaction effect is {interaction_effect}\")\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e6ab15-3088-467b-83b5-6c26ab9bb3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe668bca-7af5-4f9b-9288-4d5e5af534b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e72c55-1ccb-4a11-a1ac-4c174bc7107c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "187ba529-78aa-4002-a33d-962f6810b136",
   "metadata": {},
   "source": [
    "# Question -6 \n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b456d-dbca-45bc-af6b-5f27c9667003",
   "metadata": {},
   "source": [
    "In this scenario,  obtained an F-statistic of 5.23 and a p-value of 0.02. Here's how to interpret these results:\n",
    "\n",
    ">>. Null Hypothesis (H0): The null hypothesis in a one-way ANOVA is that there are no significant differences between the group means. In other words, all group means are equal.\n",
    "\n",
    ">>. Alternative Hypothesis (Ha): The alternative hypothesis is that there are significant differences between at least two group means.\n",
    "\n",
    "--.   Based on  results:\n",
    "\n",
    "a). F-Statistic (5.23): This is a test statistic that quantifies the ratio of the variation between group means to the variation within groups. In simpler terms, it measures whether the differences between the group means are larger than what you would expect due to random chance.\n",
    "\n",
    "b). P-Value (0.02): The p-value is the probability of obtaining an F-statistic as extreme as, or more extreme than, the one observed in your data if the null hypothesis were true. In this case, a p-value of 0.02 indicates that there is a 2% chance of observing an F-statistic as extreme as 5.23 under the assumption that there are no real differences between the group means.\n",
    "\n",
    "--.  Interpretation:\n",
    "\n",
    "With a p-value of 0.02, which is less than the common significance level of 0.05 (typically used in hypothesis testing), you would typically reject the null hypothesis (H0). This suggests that there are statistically significant differences between at least two of the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b7994-28a0-4808-9052-26b48ba4fdc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e26176-dd12-4627-9177-8df4cafc7d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff1714-5d6c-453f-8ee6-7985f1d3182c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64aff133-3a61-415b-be61-98940a90227c",
   "metadata": {},
   "source": [
    "# Question - 7\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88738728-dd6f-4868-b637-810e4a97e768",
   "metadata": {},
   "source": [
    "In a repeated measures ANOVA (Analysis of Variance), handling missing data is an important consideration because missing data can potentially bias the results and reduce the power of the analysis. Here are some common methods for handling missing data in repeated measures ANOVA and their potential consequences:\n",
    "\n",
    ">>.1 Complete Case Analysis (Listwise Deletion):\n",
    "\n",
    "* . Method: In this approach, cases (participants) with any missing data on any variable are excluded from the analysis.\n",
    "\n",
    "* . Consequences:\n",
    "\n",
    "-- . Pros: It's straightforward and does not require imputation methods.\n",
    "\n",
    "-- . Cons: Reduces the sample size, potentially leading to reduced statistical power. May introduce bias if the missing data are not missing completely at random (MCAR).\n",
    "\n",
    "\n",
    ">>.2 Pairwise Deletion:\n",
    "\n",
    "* . Method: In this approach, cases with missing data on a specific variable are excluded only from the analysis of that variable, allowing you to retain cases with partial data for other variables.\n",
    "\n",
    "* . Consequences:\n",
    "\n",
    "--. Pros: Retains more data compared to listwise deletion.\n",
    "\n",
    "--. Cons: Can lead to different sample sizes for different variables, potentially affecting the interpretation of results. May also be problematic if data are not MCAR.\n",
    "\n",
    "\n",
    ">>.3 Imputation Methods:\n",
    "\n",
    "* . Methods: Various imputation methods can be used to estimate missing values, such as mean imputation, median imputation, regression imputation, or more advanced methods like multiple imputation.\n",
    "\n",
    "* . Consequences:\n",
    "\n",
    "--. Pros: Retains the full sample size and can reduce bias in parameter estimates.\n",
    "\n",
    "--. Cons: Imputed values may introduce noise or bias if the imputation model is misspecified. The choice of imputation method can impact the results, and assumptions about the missing data mechanism (e.g., MCAR, MAR, MNAR) need to be made.\n",
    "\n",
    "\n",
    ">>.4 Maximum Likelihood Estimation (MLE):\n",
    "\n",
    "* . Method: MLE is a statistical method that estimates model parameters while accounting for missing data in the likelihood function.\n",
    "\n",
    "* . Consequences:\n",
    "\n",
    "--. Pros: Provides efficient estimates and standard errors, taking into account the uncertainty associated with missing data.\n",
    "-- . Cons: Requires more complex modeling and software that supports MLE. Assumptions about the missing data mechanism are still necessary.\n",
    "\n",
    "\n",
    ">>.5 Sensitivity Analysis:\n",
    "\n",
    "* . Method: Perform the analysis using different methods for handling missing data (e.g., listwise deletion, imputation) and compare results.\n",
    "\n",
    "* . Consequences:\n",
    "\n",
    "--. Pros: Helps assess the robustness of the findings to different missing data handling methods.\n",
    "\n",
    "--. Cons: Requires additional analyses and may not definitively resolve the issue of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48230922-d9b7-4406-a747-78b8ec43a170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16537738-a339-46fa-b8e9-07d44fe11b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f85b2-d5ad-4dac-a381-d3f8eab5129f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64575c90-ebc9-4c0e-8feb-af0b404b1880",
   "metadata": {},
   "source": [
    "# Question - 8\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b03fd-e4f8-4a64-951f-0d90e4847e44",
   "metadata": {},
   "source": [
    "1). Tukey's Honestly Significant Difference (HSD) Test:\n",
    "\n",
    "* . When to use: Tukey's HSD is a widely used post-hoc test when you have multiple groups (more than two) and you want to compare all possible pairs of group means.\n",
    "\n",
    "* . Example: In a study comparing the effectiveness of four different teaching methods, you find a significant difference among the methods using ANOVA. You can then use Tukey's HSD to identify which specific pairs of teaching methods have significantly different outcomes.\n",
    "\n",
    "\n",
    "2). Bonferroni Correction:\n",
    "\n",
    "* . When to use: Bonferroni correction is used when you want to control the familywise error rate (the probability of making at least one Type I error) in multiple comparisons.\n",
    "\n",
    "* . Example: If you are conducting multiple pairwise comparisons (e.g., comparing the means of five different groups with each other), you might use Bonferroni correction to adjust the significance level to maintain an overall alpha level (e.g., 0.05) while conducting multiple tests.\n",
    "\n",
    "\n",
    "3). Sidak Correction:\n",
    "\n",
    "* . When to use: Similar to Bonferroni correction, Sidak correction is used to control the familywise error rate. It is often used when the number of comparisons is relatively small.\n",
    "* . Example: If you are conducting a small number of pairwise comparisons (e.g., comparing three different treatments), you might use Sidak correction to adjust the significance level.\n",
    "\n",
    "\n",
    "4). Dunnett's Test:\n",
    "\n",
    "* . When to use: Dunnett's test is used when you have one control group and want to compare it with multiple treatment groups.\n",
    "\n",
    "* . Example: In a drug trial, you have one control group receiving a placebo and multiple treatment groups receiving different doses of the drug. You can use Dunnett's test to compare each treatment group to the control group.\n",
    "\n",
    "\n",
    "5). Holm-Bonferroni Method:\n",
    "\n",
    "* . When to use: Holm-Bonferroni is a sequential correction method that controls the familywise error rate. It can be used when you have a moderate number of comparisons.\n",
    "\n",
    "* . Example: If you are comparing the performance of several products in a consumer study, you might use Holm-Bonferroni correction to adjust for multiple comparisons and identify significant differences.\n",
    "\n",
    "\n",
    "6). Games-Howell Test:\n",
    "\n",
    "* . When to use: The Games-Howell test is used when you have unequal sample sizes and variances among groups.\n",
    "\n",
    "* . Example: In a study comparing the exam scores of students in different schools, if the sample sizes and variances of the schools' scores are not equal, you might use the Games-Howell test to compare the schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1727af-a709-4e33-8f54-37dd0a7499a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0351818-4149-4da2-b172-b3d5c25d5d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa8d644-e201-4881-9b00-ebd9b3ff512c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7bbdf97-095d-4277-9bdd-79e411bd4585",
   "metadata": {},
   "source": [
    "# Question - 9\n",
    "ans -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5febd00-85c4-41b1-a52e-c96f4d6bbd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f statistics is 6.229115357571769\n",
      "p value is 0.0025308938971832957\n",
      "we reject the null hypothesis , there is a significant difference between weigh loss mean of three diets\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "diet_a_group = np.random.normal(5,2,50)\n",
    "diet_b_group = np.random.normal(6,2,50)\n",
    "diet_c_group = np.random.normal(4,2,50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f_statistics , p_value = stats.f_oneway(diet_a_group,diet_b_group,diet_c_group)\n",
    "\n",
    "print(f\"f statistics is {f_statistics}\")\n",
    "print(f\"p value is {p_value}\")\n",
    "\n",
    "\n",
    "if p_value< 0.05:\n",
    "    print(\"we reject the null hypothesis , there is a significant difference between weigh loss mean of three diets\")\n",
    "    \n",
    "else:\n",
    "    print(\"failed to reject the null hypothesis , there is no significant differnce between weight loss mean of three diets \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e966c-a1ae-4600-a933-26904692359e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c14d778-98b4-4332-bef2-6edae72f79e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1c11e-8837-45cc-bf7e-536b7b257279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d58bbfae-2b70-40a9-b032-e91054efdc40",
   "metadata": {},
   "source": [
    "# Question - 10\n",
    "ans- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7c042d7-9f7a-47d4-8701-fcb0a1a71826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                sum_sq    df         F    PR(>F)\n",
      "C(Software)                   5.955556   2.0  0.140535  0.869097\n",
      "C(Experience)                12.100000   1.0  0.571054  0.451954\n",
      "C(Software):C(Experience)    39.466667   2.0  0.931306  0.398069\n",
      "Residual                   1779.866667  84.0       NaN       NaN\n",
      "There are no significant main effects of software programs or employee experience level on task completion time.There is no significant interaction effect between software programs and employee experience level on task completion time.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.seed(0) \n",
    "n_employees = 30\n",
    "n_repeats = 3\n",
    "n_total_observations = n_employees * n_repeats\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Software': np.repeat(['A', 'B', 'C'], n_employees), \n",
    "    'Experience': np.tile(['Novice', 'Experienced'], n_total_observations // 2),  \n",
    "    'Time': np.random.randint(5, 21, n_total_observations) })\n",
    "\n",
    "# Perform a two-way ANOVA\n",
    "formula1 = 'Time ~ C(Software) * C(Experience)'\n",
    "model1 = ols(formula, data=data).fit()\n",
    "anova_table1 = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "\n",
    "print(anova_table1)\n",
    "\n",
    "\n",
    "print(\"There are no significant main effects of software programs or employee experience level on task completion time.\"\n",
    "      \"There is no significant interaction effect between software programs and employee experience level on task completion time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf35999-717c-4386-804b-76e8ecdb2ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41ac2e-72ff-4f6b-bfe9-70044bea6e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d48b608-b6f5-482d-963b-c0b0210fa93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b74e1122-f64b-419a-8dbc-7737f2b5deac",
   "metadata": {},
   "source": [
    "# Question - 11\n",
    "ans - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7477d45c-00f2-4824-8958-358a05611994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic is 2.293746243557139\n",
      "p value is 0.022854674230857262\n",
      "we reject the null hypothesis , there is  significant difference between the groups \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "control_group_scores  = np.random.randint(90,100,100)\n",
    "experimental_group_Scores = np.random.randint(88,100,100)\n",
    "\n",
    "\n",
    "t_statics , p_value = stats.ttest_ind(control_group_scores , experimental_group_Scores)\n",
    "print(f\"t statistic is {t_statics}\")\n",
    "print(f\"p value is {p_value}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"we reject the null hypothesis , there is  significant difference between the groups \")\n",
    "\n",
    "else:\n",
    "    print(\"failed to reject the null hypothesis , there is no significant difference between the groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ea1b59-f8a6-4d7f-a481-abdb5e841025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "===========================================================\n",
      " group1    group2    meandiff p-adj   lower   upper  reject\n",
      "-----------------------------------------------------------\n",
      "Control Experimental    -0.98 0.0229 -1.8225 -0.1375   True\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "all_scores = np.concatenate((control_group_scores , experimental_group_Scores))\n",
    "\n",
    "group_labels  = np.array(['Control'] * len(control_group_scores) + ['Experimental'] * len(experimental_group_Scores))\n",
    "\n",
    "multicomparison = MultiComparison(all_scores , group_labels)\n",
    "\n",
    "result = multicomparison.tukeyhsd()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ff0ac7-c5e9-404f-807f-011fad754427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b93b1-d2fc-4b99-a473-80b8584b3107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c860f-3bab-418f-827c-ee8e832098e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "948aa326-2aef-44b5-9517-de835b532acc",
   "metadata": {},
   "source": [
    "# Question - 12\n",
    "ans - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55a5c95b-af2c-45fa-b813-4334b2b32477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>store_A</th>\n",
       "      <th>store_B</th>\n",
       "      <th>store_C</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>105</td>\n",
       "      <td>134</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>137</td>\n",
       "      <td>113</td>\n",
       "      <td>149</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>190</td>\n",
       "      <td>185</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>103</td>\n",
       "      <td>170</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>112</td>\n",
       "      <td>140</td>\n",
       "      <td>106</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>158</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>102</td>\n",
       "      <td>145</td>\n",
       "      <td>171</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>153</td>\n",
       "      <td>118</td>\n",
       "      <td>99</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>117</td>\n",
       "      <td>203</td>\n",
       "      <td>110</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>146</td>\n",
       "      <td>148</td>\n",
       "      <td>129</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>103</td>\n",
       "      <td>181</td>\n",
       "      <td>173</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>141</td>\n",
       "      <td>168</td>\n",
       "      <td>132</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>107</td>\n",
       "      <td>147</td>\n",
       "      <td>124</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>165</td>\n",
       "      <td>194</td>\n",
       "      <td>141</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>149</td>\n",
       "      <td>165</td>\n",
       "      <td>114</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>145</td>\n",
       "      <td>185</td>\n",
       "      <td>187</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>161</td>\n",
       "      <td>199</td>\n",
       "      <td>159</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>135</td>\n",
       "      <td>134</td>\n",
       "      <td>123</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>108</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>118</td>\n",
       "      <td>165</td>\n",
       "      <td>140</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>176</td>\n",
       "      <td>147</td>\n",
       "      <td>156</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>116</td>\n",
       "      <td>129</td>\n",
       "      <td>131</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>106</td>\n",
       "      <td>99</td>\n",
       "      <td>121</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>162</td>\n",
       "      <td>123</td>\n",
       "      <td>136</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>127</td>\n",
       "      <td>137</td>\n",
       "      <td>96</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>146</td>\n",
       "      <td>129</td>\n",
       "      <td>119</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>145</td>\n",
       "      <td>126</td>\n",
       "      <td>113</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>164</td>\n",
       "      <td>112</td>\n",
       "      <td>89</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>162</td>\n",
       "      <td>130</td>\n",
       "      <td>91</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>111</td>\n",
       "      <td>115</td>\n",
       "      <td>172</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    day  store_A  store_B  store_C  sales\n",
       "0     1      137      105      134    376\n",
       "1     2      137      113      149    399\n",
       "2     3      145      190      185    520\n",
       "3     4      145      103      170    418\n",
       "4     5      112      140      106    358\n",
       "5     6      123      123      158    404\n",
       "6     7      102      145      171    418\n",
       "7     8      153      118       99    370\n",
       "8     9      117      203      110    430\n",
       "9    10      146      148      129    423\n",
       "10   11      103      181      173    457\n",
       "11   12      141      168      132    441\n",
       "12   13      107      147      124    378\n",
       "13   14      165      194      141    500\n",
       "14   15      149      165      114    428\n",
       "15   16      145      185      187    517\n",
       "16   17      161      199      159    519\n",
       "17   18      135      134      123    392\n",
       "18   19      118      127      108    353\n",
       "19   20      118      165      140    423\n",
       "20   21      176      147      156    479\n",
       "21   22      116      129      131    376\n",
       "22   23      106       99      121    326\n",
       "23   24      162      123      136    421\n",
       "24   25      127      137       96    360\n",
       "25   26      146      129      119    394\n",
       "26   27      145      126      113    384\n",
       "27   28      164      112       89    365\n",
       "28   29      162      130       91    383\n",
       "29   30      111      115      172    398"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "np.random.seed(30)\n",
    "data = {'day': np.arange(1,31), \n",
    "       'store_A': np.random.randint(100,200,30), \n",
    "       'store_B': np.random.randint(90,210,30),\n",
    "       'store_C': np.random.randint(80,190,30),\n",
    "        \n",
    "       }\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "store_A_sales = df['store_A']\n",
    "store_B_sales = df['store_B']\n",
    "store_C_sales = df['store_C']\n",
    "\n",
    "df['sales'] = store_A_sales + store_B_sales + store_C_sales\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad5dcf1-4a76-4017-b3d5-5afa23b4c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pingouin\n",
      "  Downloading pingouin-0.5.3-py3-none-any.whl (198 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from pingouin) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from pingouin) (1.9.3)\n",
      "Requirement already satisfied: statsmodels>=0.13 in /opt/conda/lib/python3.10/site-packages (from pingouin) (0.13.5)\n",
      "Collecting outdated\n",
      "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from pingouin) (3.6.2)\n",
      "Requirement already satisfied: pandas>=1.0 in /opt/conda/lib/python3.10/site-packages (from pingouin) (1.5.2)\n",
      "Requirement already satisfied: seaborn>=0.11 in /opt/conda/lib/python3.10/site-packages (from pingouin) (0.12.1)\n",
      "Collecting pandas-flavor>=0.2.0\n",
      "  Downloading pandas_flavor-0.6.0-py3-none-any.whl (7.2 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pingouin) (1.2.0)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (1.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (22.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0->pingouin) (2022.6)\n",
      "Collecting xarray\n",
      "  Downloading xarray-2023.9.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13->pingouin) (0.5.3)\n",
      "Collecting littleutils\n",
      "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=44 in /opt/conda/lib/python3.10/site-packages (from outdated->pingouin) (65.5.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from outdated->pingouin) (2.28.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pingouin) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pingouin) (1.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels>=0.13->pingouin) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->outdated->pingouin) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->outdated->pingouin) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->outdated->pingouin) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->outdated->pingouin) (3.4)\n",
      "Building wheels for collected packages: littleutils\n",
      "  Building wheel for littleutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7028 sha256=1660368ccbcbf89128ede13b1d461ea3b222e565196501a40b2880d9a6a6dcce\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e0/3b/9c/d55ff5bc6cfbe70537c4731a22f2ee2462c2e5010b56ac9726\n",
      "Successfully built littleutils\n",
      "Installing collected packages: littleutils, tabulate, outdated, xarray, pandas-flavor, pingouin\n",
      "Successfully installed littleutils-0.2.2 outdated-0.2.2 pandas-flavor-0.6.0 pingouin-0.5.3 tabulate-0.9.0 xarray-2023.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fd119b4-29eb-4ae3-84b2-ed6a3c6cf6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pingouin in /opt/conda/lib/python3.10/site-packages (0.5.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (1.9.3)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from pingouin) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from pingouin) (1.23.5)\n",
      "Requirement already satisfied: statsmodels>=0.13 in /opt/conda/lib/python3.10/site-packages (from pingouin) (0.13.5)\n",
      "Requirement already satisfied: outdated in /opt/conda/lib/python3.10/site-packages (from pingouin) (0.2.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pingouin) (1.2.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from pingouin) (3.6.2)\n",
      "Requirement already satisfied: seaborn>=0.11 in /opt/conda/lib/python3.10/site-packages (from pingouin) (0.12.1)\n",
      "Requirement already satisfied: pandas-flavor>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from pingouin) (0.6.0)\n",
      "Requirement already satisfied: pandas>=1.0 in /opt/conda/lib/python3.10/site-packages (from pingouin) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (1.0.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (22.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (4.38.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0->pingouin) (2022.6)\n",
      "Requirement already satisfied: xarray in /opt/conda/lib/python3.10/site-packages (from pandas-flavor>=0.2.0->pingouin) (2023.9.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13->pingouin) (0.5.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from outdated->pingouin) (2.28.1)\n",
      "Requirement already satisfied: littleutils in /opt/conda/lib/python3.10/site-packages (from outdated->pingouin) (0.2.2)\n",
      "Requirement already satisfied: setuptools>=44 in /opt/conda/lib/python3.10/site-packages (from outdated->pingouin) (65.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pingouin) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pingouin) (1.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels>=0.13->pingouin) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->outdated->pingouin) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->outdated->pingouin) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->outdated->pingouin) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->outdated->pingouin) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pingouin scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3b7b6cd-5add-4b76-ae05-6f2be34491ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Anova\n",
      "==================================\n",
      "    F Value  Num DF  Den DF Pr > F\n",
      "----------------------------------\n",
      "Day  1.4945 29.0000 58.0000 0.0965\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "num_days = 30\n",
    "num_stores = 3\n",
    "\n",
    "\n",
    "store_labels = np.repeat(['A', 'B', 'C'], num_days)\n",
    "\n",
    "\n",
    "np.random.seed(0)  \n",
    "sales_data = np.random.randint(100, 1000, size=num_days * num_stores)\n",
    "\n",
    "\n",
    "day_labels = np.tile([f'Day {i}' for i in range(1, num_days + 1)], num_stores)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'Store': store_labels, 'Sales': sales_data, 'Day': day_labels})\n",
    "\n",
    "\n",
    "import pingouin as pg\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "aov = AnovaRM(df,'Sales' , 'Store' , within = ['Day'])\n",
    "result = aov.fit()\n",
    "\n",
    "print(result)\n",
    "\n",
    "if result.anova_table['Pr > F'][0] < 0.05:\n",
    "    posthoc = pg.pairwise_tukey(df , dv = 'Sales' , between = 'Store')\n",
    "    print(posthoc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b39a10b-a84f-45e3-b713-66337703694d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
